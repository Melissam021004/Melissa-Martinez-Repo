{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4360898-fbff-4ec4-8d9c-fec7082c3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027c03b8-2458-4db4-83ab-d3d2ff987706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_id(path):\n",
    "    # filename is last component\n",
    "    fname = os.path.basename(path)\n",
    "    # e.g. SOB_B_A-14-22549AB-100-001.png\n",
    "    parts = fname.split(\"-\")\n",
    "    # parts = [\"SOB_B_A\", \"14\", \"22549AB\", \"100\", \"001.png\"]\n",
    "    return parts[1] + parts[2]   # e.g. \"1422549AB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173920c5-a32b-4fb6-b16c-678cd74de128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_patient_leakage(df):\n",
    "    df[\"patient\"] = df[\"filename\"].apply(extract_patient_id)\n",
    "    \n",
    "    # Group by train/test\n",
    "    train_patients = set(df[df.grp == \"train\"].patient)\n",
    "    test_patients  = set(df[df.grp == \"test\"].patient)\n",
    "    \n",
    "    leaked = train_patients.intersection(test_patients)\n",
    "    \n",
    "    if leaked:\n",
    "        print(\"❌ PATIENT LEAKAGE DETECTED!\")\n",
    "        print(\"Patients appearing in BOTH train and test:\", leaked)\n",
    "    else:\n",
    "        print(\"✅ No patient-level leakage detected.\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Train patients:\", len(train_patients))\n",
    "    print(\"Test patients:\", len(test_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1bcee5-6013-476b-b5ba-6739dbe25430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def rebuild_patient_splits(df, n_splits=5):\n",
    "    df[\"patient\"] = df[\"filename\"].apply(extract_patient_id)\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    df[\"fold\"] = -1\n",
    "    for i, (_, test_idx) in enumerate(gkf.split(df, groups=df[\"patient\"])):\n",
    "        df.loc[test_idx, \"fold\"] = i + 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38a6a30-cd0b-481f-b91c-85226cd25b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_level_accuracy(preds, labels, patient_ids):\n",
    "    df = pd.DataFrame({\n",
    "        \"pred\": preds,\n",
    "        \"true\": labels,\n",
    "        \"patient\": patient_ids\n",
    "    })\n",
    "    # Majority vote for each patient\n",
    "    patient_votes = df.groupby(\"patient\").pred.apply(lambda x: x.mode()[0])\n",
    "    patient_truth = df.groupby(\"patient\").true.first()\n",
    "    \n",
    "    correct = (patient_votes == patient_truth).sum()\n",
    "    total = len(patient_truth)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08fbd78-50f2-41aa-b616-15789ef7f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ PATIENT LEAKAGE DETECTED!\n",
      "Patients appearing in BOTH train and test: {'1419854C', '1412312', '1422549AB', '142980', '146241', '1422549CD', '1415696', '1413993', '1412204', '148168', '1419440', '144364', '1415570', '1417901', '1416601', '1429960CD', '1418650', '1418842D', '1411520', '1416188', '1419979', '1421998EF', '1416456', '149461', '1413413', '1416716', '1415704', '1423222AB', '1421998CD', '149133', '142985', '149146', '1414015', '1421998AB', '1416184', '1417614', '145694', '1414946', '1415275', '1412773', '1414134E', '1416184CD', '1422704', '1429960AB', '15190EF', '1416196', '145287', '1419979C', '1413418DE', '1415570C', '1410926', '1416448', '1415792', '1413412', '1422549G', '144372', '1417915', '142523', '1423060AB', '1415687B', '1421978AB', '1411951', '143909', '1423060CD', '1420629', '1420636', '143411F', '1429315EF'}\n",
      "\n",
      "Train patients: 81\n",
      "Test patients: 68\n",
      "   fold  mag    grp                                           filename  \\\n",
      "0     2  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...   \n",
      "1     2  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...   \n",
      "2     2  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...   \n",
      "3     2  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...   \n",
      "4     2  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...   \n",
      "\n",
      "     patient                                           fullpath  label  \n",
      "0  1422549AB  /Users/melissamartinez/Downloads/Princ DS/Brea...      0  \n",
      "1  1422549AB  /Users/melissamartinez/Downloads/Princ DS/Brea...      0  \n",
      "2  1422549AB  /Users/melissamartinez/Downloads/Princ DS/Brea...      0  \n",
      "3  1422549AB  /Users/melissamartinez/Downloads/Princ DS/Brea...      0  \n",
      "4  1422549AB  /Users/melissamartinez/Downloads/Princ DS/Brea...      0  \n",
      "label\n",
      "1    27145\n",
      "0    12400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/Users/melissamartinez/Downloads/Princ DS/Breast Cancer Histopathological Project/Folds.csv\"\n",
    "root_dir = \"/Users/melissamartinez/Downloads/Princ DS/Breast Cancer Histopathological Project\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "check_patient_leakage(df)\n",
    "\n",
    "df[\"patient\"] = df[\"filename\"].apply(extract_patient_id)\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "df[\"fold\"] = -1\n",
    "for fold_idx, (_, test_idx) in enumerate(gkf.split(df, groups=df.patient)):\n",
    "    df.loc[test_idx, \"fold\"] = fold_idx + 1\n",
    "\n",
    "# Creating the full path of each image\n",
    "df[\"fullpath\"] = df[\"filename\"].apply(lambda x: os.path.join(root_dir, x))\n",
    "\n",
    "# Find if benign(0) or malignant(1)\n",
    "df[\"label\"] = df.filename.apply(lambda x: 0 if \"benign\" in x else 1)  \n",
    "\n",
    "# Sanity Check\n",
    "print(df.head())\n",
    "print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc04869e-7899-41e4-98f5-6d820960acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreakHISDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image from path\n",
    "        img = Image.open(row.fullpath).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = int(row.label)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2dee1f-396b-4443-b188-1afe4aa22251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer learning needs 224x224 images\n",
    "\n",
    "#Accounts for images being in different rotations and makes more variety, focuses on the density instead of the location\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(25),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ffab67-b9bb-4761-87c9-1f0a15ed649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25880 13665\n"
     ]
    }
   ],
   "source": [
    "# The csv already has them split\n",
    "train_df = df[df.grp == \"train\"]\n",
    "test_df  = df[df.grp == \"test\"]\n",
    "\n",
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1345e7da-0c3e-4082-8bbd-92a4bbd830f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BreakHISDataset(train_df, transform=train_transform)\n",
    "test_dataset  = BreakHISDataset(test_df, transform=test_transform)\n",
    "\n",
    "#Batched in 32 so my computer doesn't crash\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f77d148c-96fa-4580-ada7-b2b61e18d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f856a57b-ee11-4355-a504-76618980eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 is lighter, 50 is heavier but more accurate, although not needed bc good accuracy with 18\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # benign vs malignant\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Uses the moments from the gradients to fit the learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350d8977-f9f0-4d6c-aa4e-51f299b5cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Loss: 0.1734 | Train Acc: 0.9291\n",
      "Epoch 2/5 | Loss: 0.0820 | Train Acc: 0.9692\n",
      "Epoch 3/5 | Loss: 0.0632 | Train Acc: 0.9761\n",
      "Epoch 4/5 | Loss: 0.0469 | Train Acc: 0.9835\n",
      "Epoch 5/5 | Loss: 0.0417 | Train Acc: 0.9849\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a8d2a11-2170-45ef-a8f5-33667a150b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9933406512989389\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        pred = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "# Extract patient IDs in the correct order\n",
    "test_patients = df[df.grp == \"test\"][\"patient\"].values\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def patient_level_accuracy(preds, labels, patient_ids):\n",
    "    df_eval = pd.DataFrame({\n",
    "        \"pred\": preds,\n",
    "        \"true\": labels,\n",
    "        \"patient\": patient_ids\n",
    "    })\n",
    "    # Majority vote per patient\n",
    "    patient_pred = df_eval.groupby(\"patient\").pred.apply(lambda x: x.mode()[0])\n",
    "    patient_true = df_eval.groupby(\"patient\").true.first()\n",
    "    return (patient_pred == patient_true).mean()\n",
    "\n",
    "#pl_acc = patient_level_accuracy(preds, true_labels, test_patients)\n",
    "#print(\"Patient-Level Accuracy:\", pl_acc)\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba591c3-36b7-4a76-972b-bc6efce0482f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
